{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for post-processing\n",
    "The idea is to create a stack of neural networks. Where the second one takes the predictions from the first one as inputs. This second CNN should clean up the prediction e.g. remove noise and close roads. This is possible with a CNN because of the relation between adjecent labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dataset_preprocessing import create_dataset, extract_patches, compute_input_features, compute_output_features,load_image,img_crop_translate\n",
    "from dataset_postprocessing import unpatch\n",
    "from feature_extractors import extract_features, extract_features_2d, value_to_class, value_to_2d_class\n",
    "from visualization_helpers import *\n",
    "\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "import urllib\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as n\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES\n",
    "ROOT_DIR = \"post/\"\n",
    "TOTAL_IMAGES = 100 # Number of images to load\n",
    "TRAIN_FRACTION = 0.8 # Percentage of images used for training\n",
    "PATCH_SIZE = 16\n",
    "PATCH_TRANSLATION = 0\n",
    "FOREGROUND_THRESHOLD = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "ORIGINAL_IMAGE_WIDTH = 400\n",
    "ORIGINAL_IMAGE_HEIGHT = 400\n",
    "NUM_CHANNELS = 3\n",
    "THEANO = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dont_extract(input):\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original loaded dataset size: 20\n",
      "Creating train dataset...\n",
      "Skipping rotation.\n",
      "Skipping flip.\n",
      "Creating test dataset...\n",
      "Skipping rotation.\n",
      "Skipping flip.\n",
      "Created train dataset size: 16\n",
      "Created test dataset size: 4\n",
      "Train patches: 10000\n",
      "Test patches: 2500\n",
      "Train GT patches: 10000\n",
      "Test GT patches: 2500\n",
      "Train features: 10000\n",
      "Test features: 2500\n",
      "Train GT features: 10000\n",
      "Test GT features: 2500\n"
     ]
    }
   ],
   "source": [
    "dataset = create_dataset(ROOT_DIR, TOTAL_IMAGES, TRAIN_FRACTION)\n",
    "patches = extract_patches(dataset, PATCH_SIZE, PATCH_TRANSLATION)\n",
    "\n",
    "input_features = compute_input_features(patches[0:2], dont_extract) # train_img_patches and test_img_patches\n",
    "output_features = compute_output_features(patches[2:4], value_to_2d_class, FOREGROUND_THRESHOLD) # train_gt_img_patches and test_gt_img_patches\n",
    "\n",
    "from skimage import img_as_float\n",
    "    \n",
    "X_train = img_as_float(input_features[0])\n",
    "Y_train = output_features[0].astype(np.float32)\n",
    "X_test = img_as_float(input_features[1])\n",
    "Y_test = output_features[1].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "nb_classes = 2\n",
    "\n",
    "\n",
    "# ********** Tuning parameters: (See Network architecture as well)\n",
    "\n",
    "# Epochs to be trained\n",
    "nb_epoch = 3\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 64\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (4, 3)\n",
    "\n",
    "\"\"\"\n",
    "if \"image_dim_ordering\": is \"th\" and \"backend\": \"theano\", your input_shape must be (channels, height, width)\n",
    "if \"image_dim_ordering\": is \"tf\" and \"backend\": \"tensorflow\", your input_shape must be (height, width, channels)\n",
    "\"\"\"\n",
    "if THEANO:\n",
    "    input_shape = (NUM_CHANNELS, PATCH_SIZE, PATCH_SIZE)\n",
    "else:\n",
    "    input_shape = (PATCH_SIZE, PATCH_SIZE, NUM_CHANNELS)\n",
    "\n",
    "def train_cnn(model_name='test.h5'):\n",
    "\n",
    "\n",
    "    # **************** DEFINE THE MODEL ARCHITECTURE *******************\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Convolution layer with rectified linear activation\n",
    "    model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],border_mode='same',input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # Second convolution\n",
    "    model.add(Convolution2D(nb_filters, kernel_size[1], kernel_size[0]))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # Third convolution\n",
    "    model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[0]))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # Pooling and dropout\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # Full-connected layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # Dropout to avoid overfitting\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # Dropout to avoid overfitting\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    #Fully-connected layer to ouptut the resulting class\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adadelta', metrics=['fmeasure'])\n",
    "\n",
    "    print(X_train.shape)\n",
    "    #class_weight = auto??\n",
    "    model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, class_weight='auto', verbose=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "\n",
    "    score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "    model.save('models/' + model_name)\n",
    "    \n",
    "    data_dir = 'post/images/'\n",
    "    pred_dir = 'post/prediction/'\n",
    "    for i in range(0, 19):\n",
    "        imageid = \"pred_%.1d\" % i\n",
    "        image_filename = data_dir + imageid + \".png\"\n",
    "        if os.path.isfile(image_filename):\n",
    "            print ('Predicting ' + image_filename)\n",
    "            img = Image.open(image_filename)\n",
    "            img = np.array(img)\n",
    "\n",
    "\n",
    "            data = np.asarray(img_crop_translate(img, PATCH_SIZE, PATCH_SIZE, 0, 0))\n",
    "\n",
    "            predictions_patch = model.predict_classes(data, verbose=1)\n",
    "\n",
    "            img_prediction = label_to_img(img.shape[0], img.shape[1], \n",
    "                                          PATCH_SIZE, PATCH_SIZE, \n",
    "                                          predictions_patch)\n",
    "\n",
    "            pimg = Image.fromarray((img_prediction*255.0).astype(np.uint8))\n",
    "            pimg.save(pred_dir + \"prediction_\" + str(i) + \".png\")\n",
    "\n",
    "        else:\n",
    "            print ('File ' + image_filename + ' does not exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16, 16, 3)\n",
      "Train on 10000 samples, validate on 2500 samples\n",
      "Epoch 1/3\n",
      "10000/10000 [==============================] - 69s - loss: 0.6121 - fmeasure: 0.7100 - val_loss: 0.4747 - val_fmeasure: 0.8276\n",
      "Epoch 2/3\n",
      "10000/10000 [==============================] - 68s - loss: 0.5995 - fmeasure: 0.7125 - val_loss: 0.4803 - val_fmeasure: 0.8276\n",
      "Epoch 3/3\n",
      "10000/10000 [==============================] - 71s - loss: 0.5972 - fmeasure: 0.7125 - val_loss: 0.4909 - val_fmeasure: 0.8276\n",
      "Test score: 0.490863571787\n",
      "Test accuracy: 0.827599961281\n",
      "Predicting post/images/pred_0.png\n",
      "625/625 [==============================] - 1s     \n",
      "Predicting post/images/pred_1.png\n",
      "625/625 [==============================] - 1s     \n",
      "Predicting post/images/pred_2.png\n",
      "625/625 [==============================] - 1s     \n",
      "Predicting post/images/pred_3.png\n",
      "625/625 [==============================] - 1s     \n",
      "Predicting post/images/pred_4.png\n",
      "625/625 [==============================] - 1s     \n",
      "Predicting post/images/pred_5.png\n",
      "625/625 [==============================] - 1s     \n",
      "Predicting post/images/pred_6.png\n",
      "625/625 [==============================] - 1s     \n",
      "Predicting post/images/pred_7.png\n",
      "625/625 [==============================] - 1s     \n",
      "Predicting post/images/pred_8.png\n",
      "625/625 [==============================] - 1s     \n",
      "Predicting post/images/pred_9.png\n",
      "625/625 [==============================] - 1s     \n",
      "Predicting post/images/pred_10.png\n",
      "625/625 [==============================] - 1s     \n",
      "Predicting post/images/pred_11.png\n",
      "625/625 [==============================] - 1s     \n",
      "Predicting post/images/pred_12.png\n",
      "625/625 [==============================] - 1s     \n",
      "Predicting post/images/pred_13.png\n",
      "625/625 [==============================] - 1s     \n",
      "Predicting post/images/pred_14.png\n",
      "625/625 [==============================] - 1s     \n",
      "Predicting post/images/pred_15.png\n",
      "625/625 [==============================] - 1s     \n",
      "Predicting post/images/pred_16.png\n",
      "625/625 [==============================] - 2s     \n",
      "Predicting post/images/pred_17.png\n",
      "625/625 [==============================] - 2s     \n",
      "Predicting post/images/pred_18.png\n",
      "625/625 [==============================] - 1s     \n"
     ]
    }
   ],
   "source": [
    "train_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting post/images/pred_0.png\n",
      "(400, 400, 4)\n",
      "(625, 16, 16, 3)\n",
      "625/625 [==============================] - 1s     \n",
      "Predicting post/images/pred_1.png\n",
      "(400, 400, 4)\n",
      "(625, 16, 16, 3)\n",
      "625/625 [==============================] - 2s     \n",
      "Predicting post/images/pred_2.png\n",
      "(400, 400, 4)\n",
      "(625, 16, 16, 3)\n",
      "625/625 [==============================] - 1s     \n",
      "Predicting post/images/pred_3.png\n",
      "(400, 400, 4)\n",
      "(625, 16, 16, 3)\n",
      "512/625 [=======================>......] - ETA: 0s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-1709fb707d60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mpredictions_patch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         img_prediction = label_to_img(img.shape[0], img.shape[1], \n",
      "\u001b[0;32m/Users/mariedrieghe/anaconda/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict_classes\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m         '''\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mariedrieghe/anaconda/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mariedrieghe/anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1182\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1184\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/Users/mariedrieghe/anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m    878\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mariedrieghe/anaconda/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mariedrieghe/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mariedrieghe/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mariedrieghe/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/mariedrieghe/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mariedrieghe/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('models/test.h5')\n",
    "data_dir = 'post/images/'\n",
    "pred_dir = 'post/prediction/'\n",
    "for i in range(0, 19):\n",
    "    imageid = \"pred_%.1d\" % i\n",
    "    image_filename = data_dir + imageid + \".png\"\n",
    "    if os.path.isfile(image_filename):\n",
    "        print ('Predicting ' + image_filename)\n",
    "        img = Image.open(image_filename)\n",
    "        img = np.array(img)\n",
    "\n",
    "        print(img.shape)\n",
    "        data = np.asarray(img_crop_translate(img, PATCH_SIZE, PATCH_SIZE, 0, 0))\n",
    "        print(data.shape)\n",
    "\n",
    "        predictions_patch = model.predict_classes(data, verbose=1)\n",
    "\n",
    "        img_prediction = label_to_img(img.shape[0], img.shape[1], \n",
    "                                          PATCH_SIZE, PATCH_SIZE, \n",
    "                                          predictions_patch)\n",
    "\n",
    "        pimg = Image.fromarray((img_prediction*255.0).astype(np.uint8))\n",
    "        pimg.save(pred_dir + \"prediction_\" + str(i) + \".png\")\n",
    "\n",
    "    else:\n",
    "        print ('File ' + image_filename + ' does not exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
