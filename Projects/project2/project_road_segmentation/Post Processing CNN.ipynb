{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for post-processing\n",
    "The idea is to create a stack of neural networks. Where the second one takes the predictions from the first one as inputs. This second CNN should clean up the prediction e.g. remove noise and close roads. This is possible with a CNN because of the relation between adjecent labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from helpers.dataset_preprocessing import create_dataset, extract_patches, compute_input_features, compute_output_features,load_image,img_crop_translate\n",
    "from helpers.dataset_postprocessing import unpatch\n",
    "from helpers.feature_extractors import extract_features, extract_features_2d, value_to_class, value_to_2d_class, img_to_label\n",
    "from helpers.visualization_helpers import *\n",
    "from helpers.CNN_helpers import *\n",
    "from skimage import img_as_float, img_as_uint\n",
    "\n",
    "\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "import urllib\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as n\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES\n",
    "ROOT_DIR = \"post2/\"\n",
    "TOTAL_IMAGES = 100 # Number of images to load\n",
    "TRAIN_FRACTION = 1 # Percentage of images used for training\n",
    "PATCH_SIZE = 8\n",
    "PATCH_TRANSLATION = 0\n",
    "FOREGROUND_THRESHOLD = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "ORIGINAL_IMAGE_WIDTH = 400\n",
    "ORIGINAL_IMAGE_HEIGHT = 400\n",
    "NUM_CHANNELS = 3\n",
    "THEANO = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dont_extract(input):\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original loaded dataset size: 100\n",
      "Creating train dataset...\n",
      "Creating test dataset...\n",
      "Created train dataset size: 100\n",
      "Created test dataset size: 0\n",
      "Train patches: 250000\n",
      "Test patches: 0\n",
      "Train GT patches: 250000\n",
      "Test GT patches: 0\n",
      "Train features: 250000\n",
      "Test features: 0\n",
      "Train GT features: 250000\n",
      "Test GT features: 0\n"
     ]
    }
   ],
   "source": [
    "dataset = create_dataset(ROOT_DIR, TOTAL_IMAGES, TRAIN_FRACTION)\n",
    "patches = extract_patches(dataset, PATCH_SIZE, PATCH_TRANSLATION)\n",
    "\n",
    "input_features = compute_input_features(patches[0:2], dont_extract) # train_img_patches and test_img_patches\n",
    "output_features = compute_output_features(patches[2:4], value_to_2d_class, FOREGROUND_THRESHOLD) # train_gt_img_patches and test_gt_img_patches\n",
    "\n",
    "from skimage import img_as_float\n",
    "    \n",
    "X_train = img_as_float(input_features[0])\n",
    "Y_train = output_features[0].astype(np.float32)\n",
    "X_test = img_as_float(input_features[1])\n",
    "Y_test = output_features[1].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aa= dataset[1]\n",
    "\n",
    "imga = Image.fromarray(aa[0])\n",
    "# imga.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bb = dataset[2]\n",
    "\n",
    "imgb = Image.fromarray(bb[0])\n",
    "# imgb.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "nb_classes = 2\n",
    "\n",
    "\n",
    "# ********** Tuning parameters: (See Network architecture as well)\n",
    "\n",
    "# Epochs to be trained\n",
    "nb_epoch = 10\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 64\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (4, 3)\n",
    "\n",
    "\"\"\"\n",
    "if \"image_dim_ordering\": is \"th\" and \"backend\": \"theano\", your input_shape must be (channels, height, width)\n",
    "if \"image_dim_ordering\": is \"tf\" and \"backend\": \"tensorflow\", your input_shape must be (height, width, channels)\n",
    "\"\"\"\n",
    "if THEANO:\n",
    "    input_shape = (NUM_CHANNELS, PATCH_SIZE, PATCH_SIZE)\n",
    "else:\n",
    "    input_shape = (PATCH_SIZE, PATCH_SIZE, NUM_CHANNELS)\n",
    "\n",
    "def train_cnn(model_name='post_CNN.h5'):\n",
    "\n",
    "\n",
    "    # **************** DEFINE THE MODEL ARCHITECTURE *******************\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Convolution layer with rectified linear activation\n",
    "    model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],border_mode='same',input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # Second convolution\n",
    "    model.add(Convolution2D(nb_filters, kernel_size[1], kernel_size[0]))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # Third convolution\n",
    "    model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[0]))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # Pooling and dropout\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # Full-connected layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # Dropout to avoid overfitting\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # Dropout to avoid overfitting\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    #Fully-connected layer to ouptut the resulting class\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adadelta', metrics=['fmeasure'])\n",
    "\n",
    "    print(X_train.shape)\n",
    "    #class_weight = auto??\n",
    "    model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, class_weight='auto', verbose=1)#, validation_data=(X_test, Y_test))\n",
    "\n",
    "\n",
    "    score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "    model.save('models/' + model_name)\n",
    "    \n",
    "    data_dir = 'post2/images/'\n",
    "    pred_dir = 'post2/prediction/'\n",
    "    for i in range(80, 101):\n",
    "        num = str(i).zfill(3)\n",
    "        imageid = \"prediction_\" + num\n",
    "        image_filename = data_dir + imageid + \".png\"\n",
    "        if os.path.isfile(image_filename):\n",
    "            print ('Predicting ' + image_filename)\n",
    "            \n",
    "            # If using img_crop_translate:\n",
    "            #img = mpimg.imread(image_filename)\n",
    "            #data = np.asarray(img_crop(img, IMG_PATCH_SIZE, IMG_PATCH_SIZE))\n",
    "\n",
    "\n",
    "            # If using img_crop_translate:\n",
    "            pil_img = Image.open(image_filename)\n",
    "            pil_img = pil_img.convert('RGB')\n",
    "            img = np.array(pil_img)\n",
    "            data = np.asarray(img_as_float(img_crop_translate(img, PATCH_SIZE, PATCH_SIZE, 0, 0)), dtype='float32')\n",
    "            \n",
    "\n",
    "            predictions_patch = model.predict_classes(data, verbose=1)\n",
    "\n",
    "            img_prediction = label_to_img(img.shape[0], img.shape[1], \n",
    "                                          PATCH_SIZE, PATCH_SIZE, \n",
    "                                          predictions_patch)\n",
    "\n",
    "            pimg = Image.fromarray((img_prediction*255.0).astype(np.uint8))\n",
    "            pimg = ImageOps.invert(pimg)\n",
    "            pimg = pimg.rotate(90)\n",
    "            pimg = ImageOps.flip(pimg)\n",
    "            pimg.save(pred_dir + \"prediction_\" + num + \".png\")\n",
    "\n",
    "        else:\n",
    "            print ('File ' + image_filename + ' does not exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 8, 8, 3)\n",
      "Epoch 1/10\n",
      "250000/250000 [==============================] - 245s - loss: 0.4732 - fmeasure: 0.8165   \n",
      "Epoch 2/10\n",
      "250000/250000 [==============================] - 245s - loss: 0.4705 - fmeasure: 0.8178   \n",
      "Epoch 3/10\n",
      "250000/250000 [==============================] - 235s - loss: 0.4697 - fmeasure: 0.8178   \n",
      "Epoch 4/10\n",
      " 31488/250000 [==>...........................] - ETA: 199s - loss: 0.4680 - fmeasure: 0.8192"
     ]
    }
   ],
   "source": [
    "train_cnn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: load post procesing CNN straight from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.debugger import Tracer\n",
    "from keras.models import load_model\n",
    "model = load_model('models/ec2_model.h5')\n",
    "data_dir = 'training/images/'\n",
    "pred_dir = 'training/prediction/'\n",
    "for i in range(1, 101):\n",
    "    num = str(i).zfill(3)\n",
    "    imageid = \"satImage_\" + num\n",
    "    image_filename = data_dir + imageid + \".png\"\n",
    "    if os.path.isfile(image_filename):\n",
    "        print ('Predicting ' + image_filename)\n",
    "        # If using img_crop_translate:\n",
    "        img = mpimg.imread(image_filename)\n",
    "        data = np.asarray(img_crop(img, PATCH_SIZE, PATCH_SIZE))\n",
    "\n",
    "\n",
    "        # If using img_crop_translate:\n",
    "#         pil_img = Image.open(image_filename)\n",
    "#         pil_img = pil_img.convert('RGB')\n",
    "#         img = np.array(pil_img)\n",
    "#         data = np.asarray(img_as_float(img_crop_translate(img, PATCH_SIZE, PATCH_SIZE, 0, 0)), dtype='float32')\n",
    "\n",
    "        \n",
    "        predictions_patch = model.predict_classes(data, verbose=1)\n",
    "\n",
    "        img_prediction = label_to_img(img.shape[0], img.shape[1], \n",
    "                                          PATCH_SIZE, PATCH_SIZE, \n",
    "                                          predictions_patch)\n",
    "\n",
    "        pimg = Image.fromarray((img_prediction*255.0).astype(np.uint8))\n",
    "        pimg = ImageOps.invert(pimg)\n",
    "#         pimg = pimg.rotate(90)\n",
    "#         pimg = ImageOps.flip(pimg)\n",
    "        pimg.save(pred_dir + \"prediction_\" + num + \".png\")\n",
    "\n",
    "    else:\n",
    "        print ('File ' + image_filename + ' does not exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict_imgs(data_dir='test_images/', full_model_path='models/ec2_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_to_submission()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More post processing with morphological filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.util import img_as_ubyte\n",
    "from skimage import io\n",
    "from skimage.morphology import erosion, dilation, opening, closing, white_tophat\n",
    "from skimage.morphology import black_tophat, skeletonize, convex_hull_image\n",
    "from skimage.morphology import disk, square\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "road = img_as_ubyte(io.imread('post2/prediction/prediction_093.png', as_grey=True))\n",
    "gt = img_as_ubyte(io.imread('post2/groundtruth/satImage_093.png', as_grey=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gt_labels = img_to_label(gt, PATCH_SIZE, PATCH_SIZE, value_to_class, FOREGROUND_THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "road_labels = img_to_label(road, PATCH_SIZE, PATCH_SIZE, value_to_class, FOREGROUND_THRESHOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline right after post processing CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confusion_matrix(gt_labels, road_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f1_score(gt_labels, road_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_comparison(gt, original, filtered, filter_name):\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize=(8, 4), sharex=True, sharey=True)\n",
    "    ax1.imshow(gt, cmap=plt.cm.gray)\n",
    "    ax1.set_title('Groundtruth')\n",
    "    ax1.axis('off')\n",
    "    ax1.set_adjustable('box-forced')\n",
    "    ax2.imshow(original, cmap=plt.cm.gray)\n",
    "    ax2.set_title('original')\n",
    "    ax2.axis('off')\n",
    "    ax2.set_adjustable('box-forced')\n",
    "    ax3.imshow(filtered, cmap=plt.cm.gray)\n",
    "    ax3.set_title(filter_name)\n",
    "    ax3.axis('off')\n",
    "    ax3.set_adjustable('box-forced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selem = square(9) # segmentation element\n",
    "opened = opening(road, selem)\n",
    "plot_comparison(gt, road, opened, 'opening')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opened_labels = img_to_label(opened, PATCH_SIZE, PATCH_SIZE, value_to_class, FOREGROUND_THRESHOLD)\n",
    "f1_score(gt_labels, opened_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selem = square(9)\n",
    "closed = closing(road, selem)\n",
    "plot_comparison(gt, road, closed, 'closing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "closed_labels = img_to_label(closed, PATCH_SIZE, PATCH_SIZE, value_to_class, FOREGROUND_THRESHOLD)\n",
    "f1_score(gt_labels, closed_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selem = square(9)\n",
    "open_closed = opening(closed, selem)\n",
    "plot_comparison(gt, road, open_closed, 'opening of closed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "open_closed_labels = img_to_label(open_closed, PATCH_SIZE, PATCH_SIZE, value_to_class, FOREGROUND_THRESHOLD)\n",
    "f1_score(gt_labels, open_closed_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selem = square(35)\n",
    "closed_open_closed = closing(open_closed, selem)\n",
    "plot_comparison(gt, road, closed_open_closed, 'closing open_closed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "closed_open_closed_labels = img_to_label(closed_open_closed, PATCH_SIZE, PATCH_SIZE, value_to_class, FOREGROUND_THRESHOLD)\n",
    "f1_score(gt_labels, closed_open_closed_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
