{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from helpers.dataset_preprocessing import create_dataset, extract_patches, compute_input_features, compute_output_features\n",
    "from helpers.dataset_postprocessing import unpatch\n",
    "from helpers.feature_extractors import extract_features, extract_features_2d, value_to_class, value_to_2d_class\n",
    "from helpers.visualization_helpers import *\n",
    "from helpers.metric_helpers import calculate_train_dataset_size\n",
    "\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "import urllib\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES\n",
    "ROOT_DIR = \"new_training/\"\n",
    "TOTAL_IMAGES = 212 # Number of images to load\n",
    "TRAIN_FRACTION = 0.8 # Percentage of images used for training\n",
    "ANGLE_STEP = 0 # Gotta be 90/ANGLE_STEP needs to be an integer\n",
    "FLIP = False # Flag to signal if flipped  versions of rotated images should also be created\n",
    "PATCH_SIZE = 8\n",
    "PATCH_TRANSLATION = 0 # WARNING: this quickly explodes to enormous amount of data if small patch_translation is selected.\n",
    "FOREGROUND_THRESHOLD = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "ORIGINAL_IMAGE_WIDTH = 400\n",
    "ORIGINAL_IMAGE_HEIGHT = 400\n",
    "NUM_CHANNELS = 3\n",
    "THEANO = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted training dataset size: 424000.0000000001\n"
     ]
    }
   ],
   "source": [
    "train_dataset_size = calculate_train_dataset_size(TOTAL_IMAGES, TRAIN_FRACTION, (ORIGINAL_IMAGE_WIDTH, ORIGINAL_IMAGE_HEIGHT), (PATCH_SIZE, PATCH_SIZE), (PATCH_TRANSLATION, PATCH_TRANSLATION), ANGLE_STEP, FLIP)\n",
    "print(\"Predicted training dataset size: {0}\".format(train_dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original loaded dataset size: 212\n",
      "Creating train dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mateusz/Dropbox/EPFL/Semester I/Machnie Learning CS-433/My Answers/MachineLearning/Projects/project2/project_road_segmentation/helpers/image_modifiers.py:24: RuntimeWarning: invalid value encountered in true_divide\n",
      "  rimg = (rimg / np.max(rimg) * 255).round().astype(np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test dataset...\n",
      "Created train dataset size: 169\n",
      "Created test dataset size: 43\n"
     ]
    }
   ],
   "source": [
    "dataset = create_dataset(ROOT_DIR, TOTAL_IMAGES, TRAIN_FRACTION, rotation_angle=ANGLE_STEP, flip=FLIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train patches: 422500\n",
      "Test patches: 107500\n",
      "Train GT patches: 422500\n",
      "Test GT patches: 107500\n"
     ]
    }
   ],
   "source": [
    "patches = extract_patches(dataset, PATCH_SIZE, PATCH_TRANSLATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = np.random.permutation(np.arange(patches[0].shape[0]))\n",
    "train_size = min(1000000, int(patches[0].shape[0]))\n",
    "patches[0] = patches[0][idx[:train_size]]\n",
    "patches[2] = patches[2][idx[:train_size]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dont_extract(input):\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features: 422500\n",
      "Test features: 107500\n",
      "Train GT features: 422500\n",
      "Test GT features: 107500\n"
     ]
    }
   ],
   "source": [
    "input_features = compute_input_features(patches[0:2], dont_extract) # train_img_patches and test_img_patches\n",
    "output_features = compute_output_features(patches[2:4], value_to_2d_class, FOREGROUND_THRESHOLD) # train_gt_img_patches and test_gt_img_patches\n",
    " \n",
    "from skimage import img_as_float\n",
    "    \n",
    "X_train = img_as_float(input_features[0])\n",
    "Y_train = output_features[0].astype(np.float32)\n",
    "X_test = img_as_float(input_features[1])\n",
    "Y_test = output_features[1].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, SpatialDropout2D, GaussianDropout\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "batch_size = 500\n",
    "nb_classes = 2\n",
    "\n",
    "\n",
    "# ********** Tuning parameters: (See Network architecture as well)\n",
    "\n",
    "# Epochs to be trained\n",
    "nb_epoch = 10\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 64\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (4, 3)\n",
    "\n",
    "\"\"\"\n",
    "if \"image_dim_ordering\": is \"th\" and \"backend\": \"theano\", your input_shape must be (channels, height, width)\n",
    "if \"image_dim_ordering\": is \"tf\" and \"backend\": \"tensorflow\", your input_shape must be (height, width, channels)\n",
    "\"\"\"\n",
    "if THEANO:\n",
    "    input_shape = (NUM_CHANNELS, PATCH_SIZE, PATCH_SIZE)\n",
    "else:\n",
    "    input_shape = (PATCH_SIZE, PATCH_SIZE, NUM_CHANNELS)\n",
    "\n",
    "def train_cnn(model_name='test.h5'):\n",
    "\n",
    "\n",
    "    # **************** DEFINE THE MODEL ARCHITECTURE *******************\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Convolution layer with rectified linear activation\n",
    "    model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],border_mode='same',input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # Second convolution\n",
    "    model.add(Convolution2D(nb_filters, kernel_size[1], kernel_size[0]))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(GaussianDropout(0.25))\n",
    "\n",
    "    # Third convolution\n",
    "    model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[0]))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # Pooling and dropout\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(GaussianDropout(0.25))\n",
    "\n",
    "    # Full-connected layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    # Dropout to avoid overfitting\n",
    "    model.add(GaussianDropout(0.25))\n",
    "\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # Dropout to avoid overfitting\n",
    "    model.add(GaussianDropout(0.25))\n",
    "\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # Dropout to avoid overfitting\n",
    "    model.add(GaussianDropout(0.5))\n",
    "\n",
    "    #Fully-connected layer to ouptut the resulting class\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adadelta', metrics=['fmeasure'])\n",
    "\n",
    "    # checkpoint\n",
    "    filepath=\"models/weights-improvement-{epoch:02d}-{fmeasure:.2f}.h5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='fmeasure', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    \n",
    "    #class_weight = auto??\n",
    "    idx = np.random.permutation(np.arange(X_train.shape[0]))\n",
    "    train_size = min(300000, int(X_train.shape[0]))\n",
    "    X_train_small = X_train[idx[:train_size]]\n",
    "    Y_train_small = Y_train[idx[:train_size]]\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    featurewise_center: Boolean. Set input mean to 0 over the dataset, feature-wise.\n",
    "    samplewise_center: Boolean. Set each sample mean to 0.\n",
    "    featurewise_std_normalization: Boolean. Divide inputs by std of the dataset, feature-wise.\n",
    "    samplewise_std_normalization: Boolean. Divide each input by its std.\n",
    "    zca_whitening: Boolean. Apply ZCA whitening.\n",
    "    rotation_range: Int. Degree range for random rotations.\n",
    "    width_shift_range: Float (fraction of total width). Range for random horizontal shifts.\n",
    "    height_shift_range: Float (fraction of total height). Range for random vertical shifts.\n",
    "    shear_range: Float. Shear Intensity (Shear angle in counter-clockwise direction as radians)\n",
    "    zoom_range: Float or [lower, upper]. Range for random zoom. If a float,  [lower, upper] = [1-zoom_range, 1+zoom_range].\n",
    "    channel_shift_range: Float. Range for random channel shifts.\n",
    "    fill_mode: One of {\"constant\", \"nearest\", \"reflect\" or \"wrap\"}. Points outside the boundaries of the input are filled according to the given mode.\n",
    "    cval: Float or Int. Value used for points outside the boundaries when fill_mode = \"constant\".\n",
    "    horizontal_flip: Boolean. Randomly flip inputs horizontally.\n",
    "    vertical_flip: Boolean. Randomly flip inputs vertically.\n",
    "    rescale: rescaling factor. Defaults to None. If None or 0, no rescaling is applied, otherwise we multiply the data by the value provided (before applying any other transformation).    \"\"\"\n",
    "    train_datagen = ImageDataGenerator(\n",
    "#                             featurewise_center=True,\n",
    "#                             featurewise_std_normalization=True,\n",
    "#                             zca_whitening=True,\n",
    "#                             rotation_range=90,\n",
    "                            shear_range=0.2,\n",
    "                            width_shift_range=0.25,\n",
    "                            height_shift_range=0.25,\n",
    "                            horizontal_flip=True,\n",
    "                            vertical_flip=True)\n",
    "    \n",
    "#     test_datagen = ImageDataGenerator(\n",
    "#                             featurewise_center=True,\n",
    "#                             featurewise_std_normalization=True,\n",
    "#                             zca_whitening=True)\n",
    "\n",
    "    # compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied)\n",
    "#     train_datagen.fit(X_train_small)\n",
    "#     test_datagen.fit(X_test)\n",
    "    \n",
    "\n",
    "    # fits the model on batches with real-time data augmentation:\n",
    "    model.fit_generator(train_datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
    "                        samples_per_epoch=len(X_train), nb_epoch=nb_epoch, class_weight='auto', callbacks=callbacks_list, verbose=1, validation_data=(X_test, Y_test))\n",
    "    \n",
    "#     model.fit_generator(X_train_small, Y_train_small, batch_size=batch_size, nb_epoch=nb_epoch, class_weight='auto', callbacks=callbacks_list, verbose=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "    \n",
    "    score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "    model.save('models/' + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "422000/422500 [============================>.] - ETA: 0s - loss: 0.4257 - fmeasure: 0.8281Epoch 00000: fmeasure improved from -inf to 0.82808, saving model to models/weights-improvement-00-0.83.h5\n",
      "422500/422500 [==============================] - 286s - loss: 0.4257 - fmeasure: 0.8281 - val_loss: 0.5998 - val_fmeasure: 0.6965\n",
      "Epoch 2/10\n",
      "235000/422500 [===============>..............] - ETA: 119s - loss: 0.3497 - fmeasure: 0.8497"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-76a40d27c9d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'new_dataset_test.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-d31ec06aefaa>\u001b[0m in \u001b[0;36mtrain_cnn\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;31m# fits the model on batches with real-time data augmentation:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     model.fit_generator(train_datagen.flow(X_train, Y_train, batch_size=batch_size),\n\u001b[0;32m--> 143\u001b[0;31m                         samples_per_epoch=len(X_train), nb_epoch=nb_epoch, class_weight='auto', callbacks=callbacks_list, verbose=1, validation_data=(X_test, Y_test))\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;31m#     model.fit_generator(X_train_small, Y_train_small, batch_size=batch_size, nb_epoch=nb_epoch, class_weight='auto', callbacks=callbacks_list, verbose=1, validation_data=(X_test, Y_test))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, **kwargs)\u001b[0m\n\u001b[1;32m    905\u001b[0m                                         \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_q_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m                                         pickle_safe=pickle_safe)\n\u001b[0m\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m     def evaluate_generator(self, generator, val_samples,\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1449\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1450\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1451\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1452\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m                     \u001b[0m_stop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1224\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1226\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1227\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_cnn('new_dataset_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_cnn('new_dataset.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_cnn('1pic_rotated_5_translated_0_v2_ccn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_cnn('Random_1M_rotated_5_translated_0_v2_ccn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_cnn('Random_1M_rotated_5_translated_2_v2_ccn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
