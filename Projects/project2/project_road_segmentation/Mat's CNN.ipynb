{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from helpers.dataset_preprocessing import create_dataset, extract_patches, compute_input_features, compute_output_features\n",
    "from helpers.dataset_postprocessing import unpatch\n",
    "from helpers.feature_extractors import extract_features, extract_features_2d, value_to_class, value_to_2d_class\n",
    "from helpers.visualization_helpers import *\n",
    "\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "import urllib\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as n\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES\n",
    "ROOT_DIR = \"training/\"\n",
    "TOTAL_IMAGES = 10 # Number of images to load\n",
    "TRAIN_FRACTION = 0.8 # Percentage of images used for training\n",
    "ANGLE_STEP = 15 # Gotta be 360/ANGLE_STEP needs to be an integer\n",
    "FLIP = True # Flag to signal if flipped  versions of rotated images should also be created\n",
    "PATCH_SIZE = 8\n",
    "PATCH_TRANSLATION = 0 # WARNING: this quickly explodes to enormous amount of data if small patch_translation is selected.\n",
    "FOREGROUND_THRESHOLD = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "ORIGINAL_IMAGE_WIDTH = 400\n",
    "ORIGINAL_IMAGE_HEIGHT = 400\n",
    "NUM_CHANNELS = 6\n",
    "THEANO = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original loaded dataset size: 10\n",
      "Creating train dataset...\n",
      "Number of rotations: 24\n",
      "Flipping: True\n",
      "Creating test dataset...\n",
      "Number of rotations: 24\n",
      "Flipping: True\n",
      "Created train dataset size: 3760\n",
      "Created test dataset size: 20\n"
     ]
    }
   ],
   "source": [
    "dataset = create_dataset(ROOT_DIR, TOTAL_IMAGES, TRAIN_FRACTION, rotation_angle=ANGLE_STEP, flip=FLIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "patches = extract_patches(dataset, PATCH_SIZE, PATCH_TRANSLATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dont_extract(input):\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_features = compute_input_features(patches[0:2], extract_features) # train_img_patches and test_img_patches\n",
    "output_features = compute_output_features(patches[2:4], value_to_2d_class, FOREGROUND_THRESHOLD) # train_gt_img_patches and test_gt_img_patches\n",
    " \n",
    "from skimage import img_as_float\n",
    "    \n",
    "X_train = img_as_float(input_features[0])\n",
    "Y_train = output_features[0].astype(np.float32)\n",
    "X_test = img_as_float(input_features[1])\n",
    "Y_test = output_features[1].astype(np.float32)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "nb_classes = 2\n",
    "\n",
    "\n",
    "# ********** Tuning parameters: (See Network architecture as well)\n",
    "\n",
    "# Epochs to be trained\n",
    "nb_epoch = 10\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 64\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (4, 3)\n",
    "\n",
    "\"\"\"\n",
    "if \"image_dim_ordering\": is \"th\" and \"backend\": \"theano\", your input_shape must be (channels, height, width)\n",
    "if \"image_dim_ordering\": is \"tf\" and \"backend\": \"tensorflow\", your input_shape must be (height, width, channels)\n",
    "\"\"\"\n",
    "if THEANO:\n",
    "    input_shape = (NUM_CHANNELS, PATCH_SIZE, PATCH_SIZE)\n",
    "else:\n",
    "    input_shape = (PATCH_SIZE, PATCH_SIZE, NUM_CHANNELS)\n",
    "\n",
    "def train_cnn(model_name='test.h5'):\n",
    "\n",
    "\n",
    "    # **************** DEFINE THE MODEL ARCHITECTURE *******************\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Convolution layer with rectified linear activation\n",
    "    model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],border_mode='same',input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # Second convolution\n",
    "    model.add(Convolution2D(nb_filters, kernel_size[1], kernel_size[0]))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # Third convolution\n",
    "    model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[0]))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # Pooling and dropout\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # Full-connected layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # Dropout to avoid overfitting\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # Dropout to avoid overfitting\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    #Fully-connected layer to ouptut the resulting class\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adadelta', metrics=['fmeasure'])\n",
    "\n",
    "\n",
    "    #class_weight = auto??\n",
    "    model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch, class_weight='auto', verbose=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "\n",
    "    score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "    model.save('models/' + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
