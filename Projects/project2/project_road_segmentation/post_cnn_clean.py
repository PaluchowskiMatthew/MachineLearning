"""
	********* PCML: MINIPROJECT 2 ROAD SEGEMENTATION ***********************

	This function train a second Neural Net used as a generalization of post processing
	morphological functions. The input of the CNN are patches of size PATCH_WINDOW (number of
	patch unit used for the window) and aim to output the center pixel of this window. Labels
	are taken from the groundtruth images.
	The predictions of the first CNN are mirror padded to keep the image of the same size.
	The file post_processing_NN aims the same but without padding, which results in images smaller
	by 2 times the side of the window (called w).

	The CNN is trained using Keras, which is based on TensorFlow (or Theano if chosen).

	Function post_padded():
		Input:
			-model_name:  the name of the first neural net whose predictions are used as inputs
						  The model has to be on path: 'models/'
						  Exemple: 'main_8x8.h5'
			-train range: Range of training images to be trained on (which allows to train the
						  network on totally different images than the first network). It should be
						  of the form: [51, 100] for images from 51 to 100.
			-post_name:   Name of the saved trained network, in directory 'models/POST/'
						  Exemple: 'padded_8x8.h5'
		Ouput:
			-trained network in folder 'models/POST', as an .h5 file

	authors: Maateusz Paaluchowski, Marie Drieghe and Lazare Girardin
"""
import numpy as np

from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten, Reshape, SpatialDropout2D
from keras.layers import Convolution2D, MaxPooling2D
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ModelCheckpoint

from data_helpers import extract_data_model, load_img_gt

def train_post(model_name, post_name='dummy.h5'):

	### TUNING PARAMETERS ###

	# Training batch size
	batch_size = 128

	# Epochs to be trained
	nb_epoch = 12

	### GENERATE DATA ###
	PATCH_SIZE = 8
	PATCH_WINDOW = 21
	IMAGE_SIZE = 400
	PATCH_SIZE_FIRST = 8
	PATCH_WINDOW_FIRST = 17
	IMAGE_SIZE_FIRST = 400
	TRAIN_RATIO = 0.7
	NUM_CHANNELS = 3

	# Output classes (road and rest)
	nb_classes = 2

	input_shape = (PATCH_WINDOW, PATCH_WINDOW, 1)

	# load dataset
	imgs, gts = load_img_gt([1,10])
	data, labels = extract_data_model(model_name, PATCH_SIZE_FIRST, PATCH_WINDOW_FIRST, IMAGE_SIZE_FIRST, imgs, gts, PATCH_SIZE, PATCH_WINDOW, IMAGE_SIZE)

	# Create train and test sets
	idx = np.random.permutation(np.arange(data.shape[0]))
	train_size = int(TRAIN_RATIO*data.shape[0])
	X_train = data[idx[:train_size]]
	Y_train = labels[idx[:train_size]]
	X_test = data[idx[train_size:]]
	Y_test = labels[idx[train_size:]]

	#******** CHECK ACCURACY OF PREDICTIONS OF THE FIRST NN ***************************
	"""

	new_size = int(IMG_SIZE/PATCH_UNIT)
	w = int((PATCH_WINDOW-1)/2)
	num_images = train_range[1]-train_range[0]+1
	TP=0.
	FN=0.
	for ii in np.arange((num_images*new_size**2)):
		if pred[ii, w, w] == Y[ii, 0]:
			TP = TP+1.
		else:
			FN = FN +1.
	print("Acc on training images: ")
	print(TP/(TP+FN))
	"""

	### NEURAL NET ###

	model = Sequential()

	# Convolution layer with rectified linear activation
	model.add(Convolution2D(64, 5,5, border_mode='same', input_shape=input_shape))
	model.add(Activation('relu'))

	#Dropout to avoid overfitting
	model.add(SpatialDropout2D(0.1))

	# Second convolutional layer
	model.add(Convolution2D(128, 3,3))
	model.add(Activation('relu'))

	# Flatten the input to have dense layers
	model.add(Flatten())

	model.add(Dense(512))
	model.add(Activation('relu'))
	model.add(Dropout(0.25))

	model.add(Dense(nb_classes))
	model.add(Activation('softmax'))

	# Compile the model
	model.compile(loss='categorical_crossentropy',
			  optimizer='adadelta',
			  metrics=['fmeasure'])

	datagen = ImageDataGenerator(
		featurewise_center=False,  # set input mean to 0 over the dataset
		samplewise_center=False,  # set each sample mean to 0
		featurewise_std_normalization=False,  # divide inputs by std of the dataset
		samplewise_std_normalization=False,  # divide each input by its std
		zca_whitening=False,  # apply ZCA whitening
		rotation_range=45,  # randomly rotate images in the range (degrees, 0 to 180)
		horizontal_flip=True,  # randomly flip images
		vertical_flip=False)  # randomly flip images

	# Compute quantities required for featurewise normalization
	# (std, mean, and principal components if ZCA whitening is applied).
	datagen.fit(X_train)

	# checkpoint
	filepath="models/POST/weights-improvement-{epoch:02d}-{val_fmeasure:.2f}.h5"
	checkpoint = ModelCheckpoint(filepath, monitor='val_fmeasure', verbose=1, save_best_only=True, mode='max')
	callbacks_list = [checkpoint]

	# Fit the model on the batches generated by datagen.flow().
	model.fit_generator(datagen.flow(X_train, Y_train,
						batch_size=batch_size),
						samples_per_epoch=X_train.shape[0],
						nb_epoch=nb_epoch,
						class_weight='auto',
						verbose=1,
						validation_data=(X_test, Y_test),
						callbacks=callbacks_list)


	# Evaluate the model on the test set (excluded from training)
	score = model.evaluate(X_test, Y_test, verbose=0)
	print('Test score:', score[0])
	print('Test accuracy:', score[1])

	# Save the model
	model_path2 = 'models/POST/' + post_name
	model.save(model_path2)
	return
