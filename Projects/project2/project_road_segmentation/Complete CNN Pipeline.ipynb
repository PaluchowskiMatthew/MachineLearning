{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete CNN Pipeline\n",
    "(asumes CNN models are already created)\n",
    "\n",
    " 1. Primary CNN prediction\n",
    " 1. Post-processing with secondary CNN\n",
    " 1. Morphological post-processing\n",
    " 1. Converting to submission\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from helpers.dataset_preprocessing import create_dataset, extract_patches, compute_input_features, compute_output_features,load_image,img_crop_translate\n",
    "from helpers.dataset_postprocessing import unpatch\n",
    "from helpers.feature_extractors import extract_features, extract_features_2d, value_to_class, value_to_2d_class, img_to_label\n",
    "from helpers.visualization_helpers import *\n",
    "from helpers.CNN_helpers import *\n",
    "\n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage import io\n",
    "from skimage.morphology import erosion, dilation, opening, closing, white_tophat\n",
    "from skimage.morphology import black_tophat, skeletonize, convex_hull_image\n",
    "from skimage.morphology import disk, square\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "import urllib\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATCH_SIZE = 8\n",
    "PATCH_TRANSLATION = 0\n",
    "FOREGROUND_THRESHOLD = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "ORIGINAL_IMAGE_WIDTH = 400\n",
    "ORIGINAL_IMAGE_HEIGHT = 400\n",
    "NUM_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Primary CNN prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Load keras primary CNN model\n",
    "primary_model = load_model('models/ec2_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting test_images/test_001.png\n",
      "Predicting test_images/test_002.png\n",
      "Predicting test_images/test_003.png\n",
      "Predicting test_images/test_004.png\n",
      "Predicting test_images/test_005.png\n",
      "Predicting test_images/test_006.png\n",
      "Predicting test_images/test_007.png\n",
      "Predicting test_images/test_008.png\n",
      "Predicting test_images/test_009.png\n",
      "Predicting test_images/test_010.png\n",
      "Predicting test_images/test_011.png\n",
      "Predicting test_images/test_012.png\n",
      "Predicting test_images/test_013.png\n",
      "Predicting test_images/test_014.png\n",
      "Predicting test_images/test_015.png\n",
      "Predicting test_images/test_016.png\n",
      "Predicting test_images/test_017.png\n",
      "Predicting test_images/test_018.png\n",
      "Predicting test_images/test_019.png\n",
      "Predicting test_images/test_020.png\n",
      "Predicting test_images/test_021.png\n",
      "Predicting test_images/test_022.png\n",
      "Predicting test_images/test_023.png\n",
      "Predicting test_images/test_024.png\n",
      "Predicting test_images/test_025.png\n",
      "Predicting test_images/test_026.png\n",
      "Predicting test_images/test_027.png\n",
      "Predicting test_images/test_028.png\n",
      "Predicting test_images/test_029.png\n",
      "Predicting test_images/test_030.png\n",
      "Predicting test_images/test_031.png\n",
      "Predicting test_images/test_032.png\n",
      "Predicting test_images/test_033.png\n",
      "Predicting test_images/test_034.png\n",
      "Predicting test_images/test_035.png\n",
      "Predicting test_images/test_036.png\n",
      "Predicting test_images/test_037.png\n",
      "Predicting test_images/test_038.png\n",
      "Predicting test_images/test_039.png\n",
      "Predicting test_images/test_040.png\n",
      "Predicting test_images/test_041.png\n",
      "Predicting test_images/test_042.png\n",
      "Predicting test_images/test_043.png\n",
      "Predicting test_images/test_044.png\n",
      "Predicting test_images/test_045.png\n",
      "Predicting test_images/test_046.png\n",
      "Predicting test_images/test_047.png\n",
      "Predicting test_images/test_048.png\n",
      "Predicting test_images/test_049.png\n",
      "Predicting test_images/test_050.png\n",
      "Prediction finished.\n"
     ]
    }
   ],
   "source": [
    "predict_imgs(model=primary_model, data_dir='test_images/', prediction_root_dir='test_images_primary_prediction/', no_of_imgs=50, img_name='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Post-processing with secondary CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Load keras secondary post processing CNN model\n",
    "secondary_model = load_model('models/post_CNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting test_images_primary_prediction/prediction_001.png\n",
      "Predicting test_images_primary_prediction/prediction_002.png\n",
      "Predicting test_images_primary_prediction/prediction_003.png\n",
      "Predicting test_images_primary_prediction/prediction_004.png\n",
      "Predicting test_images_primary_prediction/prediction_005.png\n",
      "Predicting test_images_primary_prediction/prediction_006.png\n",
      "Predicting test_images_primary_prediction/prediction_007.png\n",
      "Predicting test_images_primary_prediction/prediction_008.png\n",
      "Predicting test_images_primary_prediction/prediction_009.png\n",
      "Predicting test_images_primary_prediction/prediction_010.png\n",
      "Predicting test_images_primary_prediction/prediction_011.png\n",
      "Predicting test_images_primary_prediction/prediction_012.png\n",
      "Predicting test_images_primary_prediction/prediction_013.png\n",
      "Predicting test_images_primary_prediction/prediction_014.png\n",
      "Predicting test_images_primary_prediction/prediction_015.png\n",
      "Predicting test_images_primary_prediction/prediction_016.png\n",
      "Predicting test_images_primary_prediction/prediction_017.png\n",
      "Predicting test_images_primary_prediction/prediction_018.png\n",
      "Predicting test_images_primary_prediction/prediction_019.png\n",
      "Predicting test_images_primary_prediction/prediction_020.png\n",
      "Predicting test_images_primary_prediction/prediction_021.png\n",
      "Predicting test_images_primary_prediction/prediction_022.png\n",
      "Predicting test_images_primary_prediction/prediction_023.png\n",
      "Predicting test_images_primary_prediction/prediction_024.png\n",
      "Predicting test_images_primary_prediction/prediction_025.png\n",
      "Predicting test_images_primary_prediction/prediction_026.png\n",
      "Predicting test_images_primary_prediction/prediction_027.png\n",
      "Predicting test_images_primary_prediction/prediction_028.png\n",
      "Predicting test_images_primary_prediction/prediction_029.png\n",
      "Predicting test_images_primary_prediction/prediction_030.png\n",
      "Predicting test_images_primary_prediction/prediction_031.png\n",
      "Predicting test_images_primary_prediction/prediction_032.png\n",
      "Predicting test_images_primary_prediction/prediction_033.png\n",
      "Predicting test_images_primary_prediction/prediction_034.png\n",
      "Predicting test_images_primary_prediction/prediction_035.png\n",
      "Predicting test_images_primary_prediction/prediction_036.png\n",
      "Predicting test_images_primary_prediction/prediction_037.png\n",
      "Predicting test_images_primary_prediction/prediction_038.png\n",
      "Predicting test_images_primary_prediction/prediction_039.png\n",
      "Predicting test_images_primary_prediction/prediction_040.png\n",
      "Predicting test_images_primary_prediction/prediction_041.png\n",
      "Predicting test_images_primary_prediction/prediction_042.png\n",
      "Predicting test_images_primary_prediction/prediction_043.png\n",
      "Predicting test_images_primary_prediction/prediction_044.png\n",
      "Predicting test_images_primary_prediction/prediction_045.png\n",
      "Predicting test_images_primary_prediction/prediction_046.png\n",
      "Predicting test_images_primary_prediction/prediction_047.png\n",
      "Predicting test_images_primary_prediction/prediction_048.png\n",
      "Predicting test_images_primary_prediction/prediction_049.png\n",
      "Predicting test_images_primary_prediction/prediction_050.png\n",
      "Prediction finished.\n"
     ]
    }
   ],
   "source": [
    "predict_imgs(model=secondary_model, data_dir='test_images_primary_prediction/', prediction_root_dir='test_images_secondary_prediction/', no_of_imgs=50, img_name='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction already made. If you want to rerun then delete old prediction directory.\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'test_images_primary_prediction/'\n",
    "pred_dir = 'test_images_secondary_prediction/'\n",
    "\n",
    "if not os.path.exists(pred_dir):\n",
    "    os.makedirs(pred_dir)\n",
    "\n",
    "    for i in range(1, 51):\n",
    "        num = str(i).zfill(3)\n",
    "        imageid = \"prediction_\" + num\n",
    "        image_filename = data_dir + imageid + \".png\"\n",
    "        if os.path.isfile(image_filename):\n",
    "            print ('Predicting ' + image_filename)\n",
    "            # If using img_crop_translate:\n",
    "            #img = mpimg.imread(image_filename)\n",
    "            #data = np.asarray(img_crop(img, PATCH_SIZE, PATCH_SIZE))\n",
    "\n",
    "            # If using img_crop_translate:\n",
    "            pil_img = Image.open(image_filename)\n",
    "            pil_img = pil_img.convert('RGB')\n",
    "            img = np.array(pil_img)\n",
    "            data = np.asarray(img_as_float(img_crop_translate(img, PATCH_SIZE, PATCH_SIZE, 0, 0)), dtype='float32')\n",
    "\n",
    "\n",
    "            predictions_patch = secondary_model.predict_classes(data, verbose=1)\n",
    "\n",
    "            img_prediction = label_to_img(img.shape[0], img.shape[1], \n",
    "                                              PATCH_SIZE, PATCH_SIZE, \n",
    "                                              predictions_patch)\n",
    "\n",
    "            # If using img_crop_translate:\n",
    "            #pimg = Image.fromarray((img_prediction*255.0).astype(np.uint8))\n",
    "            #pimg = ImageOps.invert(pimg)\n",
    "\n",
    "\n",
    "            # If using img_crop_translate:\n",
    "            pimg = Image.fromarray((img_prediction*255.0).astype(np.uint8))\n",
    "            \n",
    "            pimg = ImageOps.invert(pimg)\n",
    "            pimg = pimg.rotate(90)\n",
    "            pimg = ImageOps.flip(pimg)\n",
    "\n",
    "            pimg.save(pred_dir + \"prediction_\" + num + \".png\")\n",
    "\n",
    "        else:\n",
    "            print ('File ' + image_filename + ' does not exist')\n",
    "else:\n",
    "    print(\"Prediction already made. If you want to rerun then delete old prediction directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Morphological post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Morphological post-processing already made. If you want to rerun then delete old prediction directory.\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'test_images_secondary_prediction/'\n",
    "pred_dir = 'test_images_morphological_postprocessing/'\n",
    "\n",
    "if not os.path.exists(pred_dir):\n",
    "    os.makedirs(pred_dir)\n",
    "\n",
    "    for i in range(1, 51):\n",
    "        num = str(i).zfill(3)\n",
    "        imageid = \"prediction_\" + num\n",
    "        image_filename = data_dir + imageid + \".png\"\n",
    "        if os.path.isfile(image_filename):\n",
    "            \n",
    "            road = img_as_ubyte(io.imread(image_filename, as_grey=True))\n",
    "            \n",
    "            # Closing\n",
    "            selem = square(9)\n",
    "            closed = closing(road, selem)\n",
    "            \n",
    "            #Opening closed\n",
    "            selem = square(9)\n",
    "            open_closed = opening(closed, selem)\n",
    "            \n",
    "            #Closing opened-closed\n",
    "            selem = square(35)\n",
    "            closed_open_closed = closing(open_closed, selem)\n",
    "            \n",
    "            io.imsave(pred_dir + \"prediction_\" + num + \".png\", closed_open_closed)\n",
    "            \n",
    "        else:\n",
    "            print ('File ' + image_filename + ' does not exist')\n",
    "else:\n",
    "    print(\"Morphological post-processing already made. If you want to rerun then delete old prediction directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Converting to submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_images_morphological_postprocessing/prediction_001.png\n",
      "test_images_morphological_postprocessing/prediction_002.png\n",
      "test_images_morphological_postprocessing/prediction_003.png\n",
      "test_images_morphological_postprocessing/prediction_004.png\n",
      "test_images_morphological_postprocessing/prediction_005.png\n",
      "test_images_morphological_postprocessing/prediction_006.png\n",
      "test_images_morphological_postprocessing/prediction_007.png\n",
      "test_images_morphological_postprocessing/prediction_008.png\n",
      "test_images_morphological_postprocessing/prediction_009.png\n",
      "test_images_morphological_postprocessing/prediction_010.png\n",
      "test_images_morphological_postprocessing/prediction_011.png\n",
      "test_images_morphological_postprocessing/prediction_012.png\n",
      "test_images_morphological_postprocessing/prediction_013.png\n",
      "test_images_morphological_postprocessing/prediction_014.png\n",
      "test_images_morphological_postprocessing/prediction_015.png\n",
      "test_images_morphological_postprocessing/prediction_016.png\n",
      "test_images_morphological_postprocessing/prediction_017.png\n",
      "test_images_morphological_postprocessing/prediction_018.png\n",
      "test_images_morphological_postprocessing/prediction_019.png\n",
      "test_images_morphological_postprocessing/prediction_020.png\n",
      "test_images_morphological_postprocessing/prediction_021.png\n",
      "test_images_morphological_postprocessing/prediction_022.png\n",
      "test_images_morphological_postprocessing/prediction_023.png\n",
      "test_images_morphological_postprocessing/prediction_024.png\n",
      "test_images_morphological_postprocessing/prediction_025.png\n",
      "test_images_morphological_postprocessing/prediction_026.png\n",
      "test_images_morphological_postprocessing/prediction_027.png\n",
      "test_images_morphological_postprocessing/prediction_028.png\n",
      "test_images_morphological_postprocessing/prediction_029.png\n",
      "test_images_morphological_postprocessing/prediction_030.png\n",
      "test_images_morphological_postprocessing/prediction_031.png\n",
      "test_images_morphological_postprocessing/prediction_032.png\n",
      "test_images_morphological_postprocessing/prediction_033.png\n",
      "test_images_morphological_postprocessing/prediction_034.png\n",
      "test_images_morphological_postprocessing/prediction_035.png\n",
      "test_images_morphological_postprocessing/prediction_036.png\n",
      "test_images_morphological_postprocessing/prediction_037.png\n",
      "test_images_morphological_postprocessing/prediction_038.png\n",
      "test_images_morphological_postprocessing/prediction_039.png\n"
     ]
    }
   ],
   "source": [
    "predictions_to_submission(prediction_root_dir='test_images_morphological_postprocessing/', patch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
