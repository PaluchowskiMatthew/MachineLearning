{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures, normalize\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n",
    "\n",
    "from helpers.feature_extractors import extract_features, extract_features_2d, extract_features_edge, extract_features_cogrey\n",
    "from helpers.metric_helpers import compute_true_positive_rate\n",
    "from helpers.visualization_helpers import pretty_confusion, label_to_img\n",
    "from helpers.dataset_preprocessing import build_model_data, load_image, create_dataset, extract_patches, compute_input_features, compute_output_features\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers.temp_helpers import *\n",
    "\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = \"training/\"\n",
    "TRAIN_FRACTION = 0.8\n",
    "FOREGROUND_THRESHOLD = 0.25\n",
    "patch_size = 16\n",
    "width = 400\n",
    "height = 400\n",
    "n_img = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract 2d features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original loaded dataset size: 10\n",
      "X [(6250, 2)] and Y [(6250,)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1, Y1 = build_model_data(ROOT_DIR, extract_features_2d, patch_size=patch_size, n_img=n_img)\n",
    "X1 = normalize(X1)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X1)  \n",
    "X1 = scaler.transform(X1)\n",
    "mlp1 = MLPClassifier()\n",
    "mlp1.fit(X1, Y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract 6d features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original loaded dataset size: 10\n",
      "X [(6250, 6)] and Y [(6250,)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2, Y2 = build_model_data(ROOT_DIR, extract_features, patch_size=patch_size, n_img=n_img)\n",
    "X2 = normalize(X2)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X2)  \n",
    "X2 = scaler.transform(X2)\n",
    "mlp2 = MLPClassifier()\n",
    "mlp2.fit(X2, Y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add canny edge detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original loaded dataset size: 10\n",
      "X [(6250, 7)] and Y [(6250,)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3, Y3 = build_model_data(ROOT_DIR, extract_features_edge, patch_size=patch_size, n_img=n_img)\n",
    "X3 = normalize(X3)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X3)  \n",
    "X3 = scaler.transform(X3)\n",
    "mlp3 = MLPClassifier()\n",
    "mlp3.fit(X3, Y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original loaded dataset size: 10\n",
      "X [(6250, 7)] and Y [(6250,)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X4, Y4 = build_model_data(ROOT_DIR, extract_features_edge, patch_size=patch_size, n_img=n_img)\n",
    "poly = PolynomialFeatures(3)\n",
    "X4 = poly.fit_transform(X4)\n",
    "X4 = normalize(X4)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X4)  \n",
    "X4 = scaler.transform(X4)\n",
    "mlp4 = MLPClassifier()\n",
    "mlp4.fit(X4, Y4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive rate = 0.05904\n",
      "F1-score: 0.291469194313\n",
      "            t/p           road             bg\n",
      "           road           4087            335\n",
      "             bg           1459            369\n",
      "\n",
      "\n",
      "True positive rate = 0.17312\n",
      "F1-score: 0.650631389056\n",
      "            t/p           road             bg\n",
      "           road           4006            416\n",
      "             bg            746           1082\n",
      "\n",
      "\n",
      "True positive rate = 0.1664\n",
      "F1-score: 0.629349470499\n",
      "            t/p           road             bg\n",
      "           road           3985            437\n",
      "             bg            788           1040\n",
      "\n",
      "\n",
      "True positive rate = 0.16272\n",
      "F1-score: 0.648596938776\n",
      "            t/p           road             bg\n",
      "           road           4131            291\n",
      "             bg            811           1017\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [(mlp1, X1, Y1), (mlp2, X2, Y2), (mlp3, X3, Y3), (mlp4, X4, Y4)]\n",
    "\n",
    "for m in models:\n",
    "    # Predict on the training set\n",
    "    Z = m[0].predict(m[1])\n",
    "\n",
    "    TPR = compute_true_positive_rate(m[2],Z)\n",
    "    print('True positive rate = ' + str(TPR))\n",
    "    print('F1-score:', f1_score(m[2],Z))\n",
    "    pretty_confusion([\"road\", \"bg\"], m[2], Z)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation without post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY\n",
      "[ 0.71086262  0.71884984  0.7744      0.688       0.6944      0.6784\n",
      "  0.7248      0.7168      0.70352564  0.72115385]\n",
      "mean accuracy: 0.713119194724\n",
      "F1-SCORE\n",
      "[ 0.22222222  0.34328358  0.44787645  0.24902724  0.29893238  0.26470588\n",
      "  0.18269231  0.21524664  0.21757322  0.25108225]\n",
      "mean f1: 0.269264217354\n",
      "\n",
      "\n",
      "ACCURACY\n",
      "[ 0.83386581  0.85463259  0.8448      0.7568      0.8         0.7504\n",
      "  0.8064      0.808       0.78846154  0.80288462]\n",
      "mean accuracy: 0.80462445564\n",
      "F1-SCORE\n",
      "[ 0.7020649   0.75274725  0.70769231  0.55232558  0.63661972  0.52727273\n",
      "  0.60983607  0.60815047  0.58715596  0.63188406]\n",
      "mean f1: 0.631574904124\n",
      "\n",
      "\n",
      "ACCURACY\n",
      "[ 0.83067093  0.86421725  0.8464      0.7632      0.7888      0.7472\n",
      "  0.8032      0.8032      0.78525641  0.79326923]\n",
      "mean accuracy: 0.802541381994\n",
      "F1-SCORE\n",
      "[ 0.66875     0.75138122  0.69811321  0.54819277  0.62678063  0.50595238\n",
      "  0.58503401  0.6025641   0.56962025  0.60188088]\n",
      "mean f1: 0.615826944891\n",
      "\n",
      "\n",
      "ACCURACY\n",
      "[ 0.80990415  0.81629393  0.8624      0.7952      0.7568      0.7904\n",
      "  0.7888      0.8144      0.80448718  0.74198718]\n",
      "mean accuracy: 0.798067244204\n",
      "F1-SCORE\n",
      "[ 0.59813084  0.63037249  0.71197411  0.62352941  0.46099291  0.58169935\n",
      "  0.49420849  0.59661017  0.56578947  0.53521127]\n",
      "mean f1: 0.579851851495\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in models:\n",
    "    cr_val = cross_val_score(m[0], m[1], m[2], cv=10, scoring='accuracy')\n",
    "    print('ACCURACY')\n",
    "    print(cr_val)\n",
    "    print('mean accuracy:', cr_val.mean())\n",
    "    cr_val = cross_val_score(m[0], m[1], m[2], cv=10, scoring='f1')\n",
    "    print('F1-SCORE')\n",
    "    print(cr_val)\n",
    "    print('mean f1:', cr_val.mean())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage.morphology import *\n",
    "def postprocessing(Z, w, h, patch_size):\n",
    "    n_patch = np.int(w/patch_size)\n",
    "    Z = Z.reshape(-1,n_patch*n_patch)\n",
    "    \n",
    "    Z = np.apply_along_axis(post_image, arr=Z, axis=1)\n",
    "    Z = Z.reshape(-1,1)\n",
    "    return Z\n",
    "\n",
    "def post_image(Z):\n",
    "    binary_closing(Z, out=Z)\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation with post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def cross_validation(X, Y, mlp, cv=10, post=False, verbose=False):\n",
    "    tot_f1 = 0\n",
    "    tot_acc = 0\n",
    "    kf = KFold(n_splits=cv)\n",
    "\n",
    "    for k, (train, test) in enumerate(kf.split(X)):\n",
    "        x_train = X[train]\n",
    "        x_test = X[test]\n",
    "        y_train = Y[train]\n",
    "        y_test = Y[test]\n",
    "\n",
    "        mlp.fit(x_train,y_train)\n",
    "\n",
    "        z = mlp.predict(x_test)\n",
    "\n",
    "        if post:\n",
    "            z = postprocessing(z, width, height, patch_size)\n",
    "\n",
    "        Zn = np.nonzero(z)[0]\n",
    "        Yn = np.nonzero(y_test)[0]\n",
    "\n",
    "        TPR = len(list(set(Yn) & set(Zn))) / float(len(z))\n",
    "        f1 = f1_score(y_test,z)\n",
    "        acc = accuracy_score(y_test,z)\n",
    "\n",
    "        tot_f1 = tot_f1 + f1\n",
    "        tot_acc = tot_acc + acc\n",
    "        \n",
    "        if verbose:\n",
    "            print('K: ', k)\n",
    "            print('True positive rate = ' + str(TPR))\n",
    "            print('F1-score:', f1)\n",
    "            print('accuracy score:', acc)\n",
    "            print('\\n')\n",
    "\n",
    "    avg_f1 = tot_f1/cv\n",
    "    avg_acc = tot_acc/cv\n",
    "    \n",
    "    print('Average Accuracy score:', avg_acc)\n",
    "    print('Average F1-score:', avg_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Accuracy score: 0.70864\n",
      "Average F1-score: 0.268947155534\n",
      "Average Accuracy score: 0.70752\n",
      "Average F1-score: 0.286507705869\n",
      "\n",
      "Average Accuracy score: 0.80592\n",
      "Average F1-score: 0.63569299633\n",
      "Average Accuracy score: 0.80144\n",
      "Average F1-score: 0.655640240535\n",
      "\n",
      "Average Accuracy score: 0.79792\n",
      "Average F1-score: 0.611084346614\n",
      "Average Accuracy score: 0.79872\n",
      "Average F1-score: 0.641035679034\n",
      "\n",
      "Average Accuracy score: 0.80544\n",
      "Average F1-score: 0.606063217682\n",
      "Average Accuracy score: 0.79696\n",
      "Average F1-score: 0.598515385617\n"
     ]
    }
   ],
   "source": [
    "for m in models:\n",
    "    print()\n",
    "    cross_validation(m[1],m[2],m[0],post=False)\n",
    "    cross_validation(m[1],m[2],m[0],post=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation for n_neighbors and degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original loaded dataset size: 10\n"
     ]
    }
   ],
   "source": [
    "X0, Y0 = build_model_data(ROOT_DIR, extract_features_cogrey, patch_size=patch_size, n_img=n_img)\n",
    "degrees = [2, 3, 5, 7]\n",
    "n_neighbors = [3, 5, 7, 10]\n",
    "for d in degrees:\n",
    "    poly = PolynomialFeatures(d)\n",
    "    X = poly.fit_transform(X0)\n",
    "    X = normalize(X)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)  \n",
    "    X = scaler.transform(X)\n",
    "\n",
    "    for n in n_neighbors:\n",
    "        mlp = MLPClassifier()\n",
    "        \n",
    "        cr_val = cross_val_score(mlp, X, Y0, cv=10, scoring='f1')\n",
    "        print('F1-SCORE')\n",
    "        print(cr_val)\n",
    "        print('mean f1:', cr_val.mean())\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def predict(neigh):\n",
    "    X, Y = build_model_data(ROOT_DIR, extract_features_edge, patch_size=patch_size, n_img=1000)\n",
    "    poly = PolynomialFeatures(3)\n",
    "    X = poly.fit_transform(X)\n",
    "    X = normalize(X)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)  \n",
    "    X = scaler.transform(X)\n",
    "    mlp = MLPClassifier()\n",
    "    \n",
    "    cut = int(0.8*(Y.shape[0]))\n",
    "    X_train = X[0:cut]\n",
    "    X_test = X[cut:]\n",
    "    Y_train = Y[0:cut]\n",
    "    Y_test = Y[cut:]\n",
    "    mlp.fit(X_train, Y_train)\n",
    "\n",
    "    z = mlp.predict(X_test)\n",
    "    z = postprocessing(z, width, height, patch_size)\n",
    "    \n",
    "    return z, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z, Y_test = predict(mlp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_size = int(width/patch_size)*int(height/patch_size)\n",
    "for ix, i in enumerate(range(0,z.shape[0],pred_size)):\n",
    "    pred = z[i:i+pred_size]\n",
    "    im = label_to_img(width, height, patch_size, patch_size, pred)\n",
    "    plt.imsave('post/images/pred_{}'.format(ix), im, cmap='Greys_r')\n",
    "    \n",
    "for ix, i in enumerate(range(0,Y_test.shape[0],pred_size)):\n",
    "    pred = Y_test[i:i+pred_size]\n",
    "    im = label_to_img(width, height, patch_size, patch_size, pred)\n",
    "    pimg = Image.fromarray((im*255.0).astype(np.uint8))\n",
    "    pimg.save('post/groundtruth/pred_{}.png'.format(ix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XX, YY = build_model_data(extract_features_2d, patch_size=patch_size, n_img=n_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
